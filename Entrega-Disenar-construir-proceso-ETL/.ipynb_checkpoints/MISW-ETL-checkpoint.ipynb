{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6fa175a-f01b-4162-976d-2138ec4b9f9b",
   "metadata": {},
   "source": [
    "# Tarea: Construir un proceso ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f313b7-0f36-4e4f-95e0-76deacc3f0d9",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "    Objetivo\n",
    "       Realizar un proceso ETL básico en Pyspark\n",
    "\t¿Para qué?\n",
    "      Practicar lo aprendido en el tutorial de ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c5256e-781e-4594-b624-72e8f19db5f0",
   "metadata": {},
   "source": [
    "## Configuración e importe de paquetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4d935c0-e7d8-4180-b670-bad19e94e024",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\estudiante\\anaconda3\\envs\\Tutoriales\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark import SparkContext, SparkConf, SQLContext\n",
    "from pyspark.sql.types import FloatType, StringType, IntegerType, DateType, TimestampType\n",
    "from pyspark.sql.functions import udf, col, countDistinct, length, isnan, when, count, max as spark_max, to_date, year, to_timestamp, expr, substring, min, corr\n",
    "import pyspark.sql.functions as f\n",
    "import os \n",
    "from datetime import datetime\n",
    "from pyspark.sql import types as t\n",
    "from pandas_profiling import ProfileReport\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bd2cdaf-8a09-49a0-b80b-a920caae16c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración servidor base de datos transaccional\n",
    "db_user = 'Estudiante_30_202413'\n",
    "db_psswd = 'MISO_aabb1122'\n",
    "source_db_connection_string = 'jdbc:mysql://157.253.236.116:8080/WWImportersTransactional'\n",
    "dest_db_connection_string = 'jdbc:mysql://157.253.236.116:8080/Estudiante_30_202413'\n",
    "# Driver de conexion\n",
    "path_jar_driver = 'C:\\Program Files (x86)\\MySQL\\Connector J 8.0\\mysql-connector-java-8.0.28.jar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd7cd31d-2057-428b-9930-4a0f91513c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\estudiante\\anaconda3\\envs\\Tutoriales\\lib\\site-packages\\pyspark\\sql\\context.py:79: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "#Configuración de la sesión\n",
    "conf=SparkConf() \\\n",
    "    .set('spark.driver.extraClassPath', path_jar_driver)\n",
    "spark_context = SparkContext(conf=conf)\n",
    "sql_context = SQLContext(spark_context)\n",
    "spark = sql_context.sparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8878120a-8896-4083-a37f-eaa26d362eab",
   "metadata": {},
   "source": [
    "### Conexión y carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fa3215-8d07-4c7b-9897-091479c3279d",
   "metadata": {},
   "source": [
    "Definicion de las funciónes para conexión y cargue de dataframes desde la base de datos origen y luego la función para guardar un dataframe en una tabla de la base de datos destino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f07e428-c2d7-4f54-94d3-bf2a3e63017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obterner_dataframe_desde_csv(_PATH, _sep):\n",
    "    return spark.read.load(_PATH, format=\"csv\", sep=_sep, inferSchema=\"true\", header='true')\n",
    "\n",
    "def obtener_dataframe_de_bd(db_connection_string, sql, db_user, db_psswd):\n",
    "    df_bd = spark.read.format('jdbc')\\\n",
    "        .option('url', db_connection_string) \\\n",
    "        .option('dbtable', sql) \\\n",
    "        .option('user', db_user) \\\n",
    "        .option('password', db_psswd) \\\n",
    "        .option('driver', 'com.mysql.cj.jdbc.Driver') \\\n",
    "        .load()\n",
    "    return df_bd\n",
    "\n",
    "def guardar_db(db_connection_string, df, tabla, db_user, db_psswd):\n",
    "    df.select('*').write.format('jdbc') \\\n",
    "      .mode('append') \\\n",
    "      .option('url', db_connection_string) \\\n",
    "      .option('dbtable', tabla) \\\n",
    "      .option('user', db_user) \\\n",
    "      .option('password', db_psswd) \\\n",
    "      .option('driver', 'com.mysql.cj.jdbc.Driver') \\\n",
    "      .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30295981-17dc-4174-abb1-65cda4386f50",
   "metadata": {},
   "source": [
    "## Dimensiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecca3879-c97f-482c-8cc6-18d3f4835df5",
   "metadata": {},
   "source": [
    "### Proveedor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677a4515-e923-4f32-96e4-2d31d67cf76b",
   "metadata": {},
   "source": [
    "La dimensión Proveedor contiene información detallada sobre los proveedores que suministran productos a la empresa. Esta dimensión es fundamental para el análisis de la relación con los proveedores, incluyendo aspectos como la categoría del proveedor, los datos de contacto y los términos de pago. La implementación del ETL para esta dimensión se centra en asegurar la calidad y consistencia de los datos, eliminando duplicados y corrigiendo errores comunes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6209baf7-657e-470c-923c-c1610ce96340",
   "metadata": {},
   "source": [
    "#### Extracción\n",
    "En esta fase, se extraen los datos de la tabla Proveedores de la base de datos transaccional WWImportersTransactional. La extracción incluye los campos necesarios para el análisis y omite aquellos que no son relevantes para la dimensión de proveedor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cdd5742-c2ea-449b-a993-570e95950828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------------+--------------------------+------------------------+--------+------------+----------------+\n",
      "|ProveedorID|     NombreProveedor|CategoriaProveedorID|PersonaContactoPrincipalID|PersonaContactoAlternoID|DiasPago|CodigoPostal|UltimaEdicionPor|\n",
      "+-----------+--------------------+--------------------+--------------------------+------------------------+--------+------------+----------------+\n",
      "|          4|      Fabrikam, Inc.|                   4|                        27|                      28|      30|       40351|               1|\n",
      "|          5|Graphic Design In...|                   2|                        29|                      30|      14|       64847|               1|\n",
      "|          7|       Litware, Inc.|                   5|                        33|                      34|      30|       95245|               1|\n",
      "|          9|      Nod Publishers|                   2|                        37|                      38|       7|       27906|               1|\n",
      "|         10|Northwind Electri...|                   3|                        39|                      40|      30|        7860|               1|\n",
      "|         12|   The Phone Company|                   2|                        43|                      44|      30|       56732|               1|\n",
      "|         13|      Woodgrove Bank|                   7|                        45|                      46|       7|       94101|               1|\n",
      "|          2|       Contoso, Ltd.|                   2|                        23|                      24|      -7|       98253|               1|\n",
      "|          6| Humongous Insurance|                   9|                        31|                      32|     -14|       37770|               1|\n",
      "|          8|  Lucerne Publishing|                   2|                        35|                      36|     -30|       37659|               1|\n",
      "|          1| A Datum Corporation|                   2|                        21|                      22|     -14|       46077|               1|\n",
      "|         11|       Trey Research|                   8|                        41|                      42|      -7|       57543|               1|\n",
      "|          3|Consolidated Mess...|                   6|                        25|                      26|     -30|       94101|               1|\n",
      "+-----------+--------------------+--------------------+--------------------------+------------------------+--------+------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definir la consulta SQL para extraer solo los datos necesarios de la tabla Proveedores\n",
    "sql_query_proveedores = \"\"\"\n",
    "(SELECT \n",
    "    ProveedorID, \n",
    "    NombreProveedor, \n",
    "    CategoriaProveedorID, \n",
    "    PersonaContactoPrincipalID, \n",
    "    PersonaContactoAlternoID, \n",
    "    DiasPago, \n",
    "    CodigoPostal, \n",
    "    UltimaEdicionPor\n",
    "FROM proveedores) AS Proveedores\"\"\"\n",
    "\n",
    "# Extraer los datos de la tabla Proveedores utilizando la función definida previamente\n",
    "df_proveedores = obtener_dataframe_de_bd(source_db_connection_string, sql_query_proveedores, db_user, db_psswd)\n",
    "\n",
    "# Mostrar los primeros registros para verificar la extracción\n",
    "df_proveedores.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafd14e6-a5ff-4520-bd82-22086acf08f0",
   "metadata": {},
   "source": [
    "#### Transformación\n",
    "En esta fase, los datos extraídos de la tabla Proveedores se transformarán para corregir errores y asegurar la calidad de los datos. Las transformaciones incluyen la eliminación de registros duplicados, la corrección de valores negativos en el campo DiasPago, la estandarización del formato de fechas y la combinación de registros de proveedores duplicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2a51041-0eb3-4775-970f-168c3c54a02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+--------------------+--------------------------+------------------------+--------+------------+\n",
      "|ID_Proveedor_T|     NombreProveedor|           Categoria|PersonaContactoPrincipalID|PersonaContactoAlternoID|DiasPago|CodigoPostal|\n",
      "+--------------+--------------------+--------------------+--------------------------+------------------------+--------+------------+\n",
      "|             1| A Datum Corporation| productos novedosos|                        21|                      22|      14|       46077|\n",
      "|             2|       Contoso, Ltd.| productos novedosos|                        23|                      24|       7|       98253|\n",
      "|             5|Graphic Design In...| productos novedosos|                        29|                      30|      14|       64847|\n",
      "|             8|  Lucerne Publishing| productos novedosos|                        35|                      36|      30|       37659|\n",
      "|             9|      Nod Publishers| productos novedosos|                        37|                      38|       7|       27906|\n",
      "|            12|   The Phone Company| productos novedosos|                        43|                      44|      30|       56732|\n",
      "|            10|Northwind Electri...|            juguetes|                        39|                      40|      30|        7860|\n",
      "|             4|      Fabrikam, Inc.|                ropa|                        27|                      28|      30|       40351|\n",
      "|             7|       Litware, Inc.|            embalaje|                        33|                      34|      30|       95245|\n",
      "|             3|Consolidated Mess...|servicios de mens...|                        25|                      26|      30|       94101|\n",
      "|            13|      Woodgrove Bank|servicios financi...|                        45|                      46|       7|       94101|\n",
      "|            11|       Trey Research|servicios de mark...|                        41|                      42|       7|       57543|\n",
      "|             6| Humongous Insurance|servicios de seguros|                        31|                      32|      14|       37770|\n",
      "+--------------+--------------------+--------------------+--------------------------+------------------------+--------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Eliminar registros duplicados basados en ProveedorID\n",
    "df_proveedores = df_proveedores.dropDuplicates([\"ProveedorID\"])\n",
    "\n",
    "# Corregir valores negativos en el campo DiasPago\n",
    "df_proveedores = df_proveedores.withColumn(\"DiasPago\", \n",
    "                                           f.when(df_proveedores[\"DiasPago\"] < 0, \n",
    "                                                  df_proveedores[\"DiasPago\"] * -1).otherwise(df_proveedores[\"DiasPago\"]))\n",
    "\n",
    "# Combinar registros de proveedores con nombres duplicados (con y sin \"Inc\" o \"Ltd\")\n",
    "# Primero, crear una columna estandarizada para nombres de proveedores\n",
    "df_proveedores = df_proveedores.withColumn(\"NombreProveedorEstandarizado\", \n",
    "                                           f.trim(f.regexp_replace(f.col(\"NombreProveedor\"), \"Inc|Ltd\", \"\")))\n",
    "\n",
    "# Agrupar por el nombre estandarizado y seleccionar los valores no nulos más recientes\n",
    "window_spec = Window.partitionBy(\"NombreProveedorEstandarizado\").orderBy(f.desc(\"UltimaEdicionPor\"))\n",
    "df_proveedores = df_proveedores.withColumn(\"row_number\", f.row_number().over(window_spec)).filter(f.col(\"row_number\") == 1).drop(\"row_number\")\n",
    "\n",
    "# Unir con la tabla CategoriasProveedores para obtener el nombre de la categoría\n",
    "sql_query_categorias = \"\"\"\n",
    "(SELECT \n",
    "    CategoriaProveedorID, \n",
    "    CategoriaProveedor \n",
    "FROM CategoriasProveedores) AS CategoriasProveedores\"\"\"\n",
    "df_categorias = obtener_dataframe_de_bd(source_db_connection_string, sql_query_categorias, db_user, db_psswd)\n",
    "\n",
    "df_proveedores = df_proveedores.join(df_categorias, \"CategoriaProveedorID\", \"left\")\n",
    "\n",
    "# Seleccionar y renombrar columnas para la tabla destino\n",
    "df_proveedores = df_proveedores.select(\n",
    "    f.col(\"ProveedorID\").alias(\"ID_Proveedor_T\"),\n",
    "    f.col(\"NombreProveedor\"),\n",
    "    f.col(\"CategoriaProveedor\").alias(\"Categoria\"),\n",
    "    f.col(\"PersonaContactoPrincipalID\"),\n",
    "    f.col(\"PersonaContactoAlternoID\"),\n",
    "    f.col(\"DiasPago\"),\n",
    "    f.col(\"CodigoPostal\")\n",
    ")\n",
    "\n",
    "# Mostrar los primeros registros transformados\n",
    "df_proveedores.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff01dcae-bfec-43ce-8c67-03c1e8041f38",
   "metadata": {},
   "source": [
    "#### Carga \n",
    "En esta fase, los datos transformados de la tabla Proveedores se cargarán en la tabla de dimensión ETL_Proveedor en la base de datos de destino. Se asegurará que los datos se inserten correctamente y se verificará que la estructura de la tabla de destino coincida con los datos transformados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e524f65b-e858-4c9a-9694-b8e16f4dbaf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados exitosamente en la tabla ETL_Proveedor\n"
     ]
    }
   ],
   "source": [
    "tabla_destino = \"ETL_Proveedor\"\n",
    "guardar_db(dest_db_connection_string, df_proveedores, tabla_destino, db_user, db_psswd)\n",
    "print(\"Datos cargados exitosamente en la tabla ETL_Proveedor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54f777d-82c5-4188-b683-e7f3a447123a",
   "metadata": {},
   "source": [
    "### TipoTransaccion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5974f5c2-65d1-4346-86dd-5f6f64e02c14",
   "metadata": {},
   "source": [
    "La dimensión TipoTransaccion contiene información sobre los diferentes tipos de transacciones que pueden ocurrir en el sistema. Esta dimensión es fundamental para categorizar y analizar las transacciones en el contexto de las operaciones comerciales. La implementación del ETL para esta dimensión se centra en asegurar la calidad de los datos, eliminando duplicados y estandarizando los nombres de las transacciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52f4542-648c-468d-9d1d-e26af1a62d71",
   "metadata": {},
   "source": [
    "#### Extracción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276d51f8-8fa8-4b94-9492-82036edaee59",
   "metadata": {},
   "source": [
    "En esta fase, se extraen los datos de la tabla TiposTransaccion de la base de datos transaccional WWImportersTransactional. La extracción incluye solo los campos necesarios para el análisis y omite aquellos que no son relevantes para la dimensión de tipo de transacción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d19d597-9d76-4b75-bb60-5b561fe69daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------------------+\n",
      "|TipoTransaccionID|TipoTransaccionNombre|\n",
      "+-----------------+---------------------+\n",
      "|                2| Customer Credit Note|\n",
      "|                3| Customer Payment ...|\n",
      "|                4|      Customer Refund|\n",
      "|                5|     Supplier Invoice|\n",
      "|                6| Supplier Credit Note|\n",
      "|                7| Supplier Payment ...|\n",
      "|                8|      Supplier Refund|\n",
      "|                9|       Stock Transfer|\n",
      "|               10|          Stock Issue|\n",
      "|               11|        Stock Receipt|\n",
      "|               12| Stock Adjustment ...|\n",
      "|               13|      Customer Contra|\n",
      "+-----------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definir la consulta SQL para extraer solo los datos necesarios\n",
    "sql_query_tipos_transaccion = \"\"\"\n",
    "(SELECT \n",
    "    TipoTransaccionID, \n",
    "    TipoTransaccionNombre \n",
    "FROM TiposTransaccion) AS TiposTransaccion\"\"\"\n",
    "# Extraer los datos de la tabla y muestra\n",
    "df_tipos_transaccion = obtener_dataframe_de_bd(source_db_connection_string, sql_query_tipos_transaccion, db_user, db_psswd)\n",
    "df_tipos_transaccion.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405c96e7-2de0-44ce-b2c4-f7f89ef15022",
   "metadata": {},
   "source": [
    "#### Transformación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3403ae-5cda-48d9-9d20-be7d6e090be2",
   "metadata": {},
   "source": [
    "En esta fase, los datos extraídos de la tabla TiposTransaccion se transformarán para corregir errores y asegurar la calidad de los datos. Las transformaciones incluyen la eliminación de registros duplicados y la estandarización de los nombres de transacción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51a3a996-2bf3-42e2-bbc0-16e19f7108c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+--------------------+\n",
      "|ID_Tipo_Transaccion_T|                Tipo|\n",
      "+---------------------+--------------------+\n",
      "|                    2|CUSTOMER CREDIT NOTE|\n",
      "|                    3|CUSTOMER PAYMENT ...|\n",
      "|                    4|     CUSTOMER REFUND|\n",
      "|                    5|    SUPPLIER INVOICE|\n",
      "|                    6|SUPPLIER CREDIT NOTE|\n",
      "|                    7|SUPPLIER PAYMENT ...|\n",
      "|                    8|     SUPPLIER REFUND|\n",
      "|                    9|      STOCK TRANSFER|\n",
      "|                   10|         STOCK ISSUE|\n",
      "|                   11|       STOCK RECEIPT|\n",
      "|                   12|STOCK ADJUSTMENT ...|\n",
      "|                   13|     CUSTOMER CONTRA|\n",
      "+---------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Eliminar registros duplicados basados en TipoTransaccionID\n",
    "df_tipos_transaccion = df_tipos_transaccion.dropDuplicates([\"TipoTransaccionID\"])\n",
    "# Estandarizar los nombres de transacción\n",
    "df_tipos_transaccion = df_tipos_transaccion.withColumn(\"TipoTransaccionNombre\", f.upper(f.col(\"TipoTransaccionNombre\")))\n",
    "# Seleccionar y renombrar columnas para la tabla destino\n",
    "df_tipos_transaccion = df_tipos_transaccion.select(\n",
    "    f.col(\"TipoTransaccionID\").alias(\"ID_Tipo_Transaccion_T\"),\n",
    "    f.col(\"TipoTransaccionNombre\").alias(\"Tipo\")\n",
    ")\n",
    "df_tipos_transaccion.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7265b30-7d87-476c-be7a-1180f51fe466",
   "metadata": {},
   "source": [
    "#### Carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90de7252-3e39-4da0-a476-14a2bc53aa8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados exitosamente en la tabla ETL_TipoTransaccion\n"
     ]
    }
   ],
   "source": [
    "tabla_destino = \"ETL_TipoTransaccion\"\n",
    "guardar_db(dest_db_connection_string, df_tipos_transaccion, tabla_destino, db_user, db_psswd)\n",
    "print(\"Datos cargados exitosamente en la tabla ETL_TipoTransaccion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe78c7f-d88b-4a68-abe4-6a340ea93d6e",
   "metadata": {},
   "source": [
    "### Fecha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552d92f2-60c4-41ef-a362-df2aab563b7e",
   "metadata": {},
   "source": [
    "La dimensión Fecha contiene información detallada sobre las fechas relevantes para las transacciones. Esta dimensión es fundamental para el análisis temporal de los datos, permitiendo segmentar y analizar las transacciones por día, mes, año y otros componentes temporales. La implementación del ETL para esta dimensión se centra en asegurar la integridad y consistencia de las fechas, eliminando duplicados y estandarizando los formatos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b600a8b7-7663-48bb-9ea2-234dd7afbd0f",
   "metadata": {},
   "source": [
    "#### Extracción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e031d1-2255-4b2f-bcb9-259be67eb2d5",
   "metadata": {},
   "source": [
    "En esta fase, se extraen las fechas de las transacciones de la tabla movimientos de la base de datos transaccional WWImportersTransactional. La extracción incluye solo el campo necesario FechaTransaccion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "773973a8-f55b-4221-95c5-becb0657cb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|FechaTransaccion|\n",
      "+----------------+\n",
      "|     Jan 20,2014|\n",
      "|     Jan 28,2014|\n",
      "|     Jan 28,2014|\n",
      "|     Jan 28,2014|\n",
      "|     Jan 28,2014|\n",
      "|     Feb 01,2014|\n",
      "|     Feb 01,2014|\n",
      "|     Mar 25,2014|\n",
      "|     Mar 25,2014|\n",
      "|     Mar 25,2014|\n",
      "|     Mar 25,2014|\n",
      "|     Mar 25,2014|\n",
      "|     Mar 25,2014|\n",
      "|     Mar 25,2014|\n",
      "|     Mar 25,2014|\n",
      "|     Mar 25,2014|\n",
      "|     Mar 25,2014|\n",
      "|     Mar 25,2014|\n",
      "|     Mar 25,2014|\n",
      "|     Mar 25,2014|\n",
      "+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_query_fecha = \"\"\"\n",
    "(SELECT \n",
    "    FechaTransaccion \n",
    "FROM movimientos_v2) AS movimientos\"\"\"\n",
    "df_fecha = obtener_dataframe_de_bd(source_db_connection_string, sql_query_fecha, db_user, db_psswd)\n",
    "df_fecha.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8596eaff-056f-4c0a-b356-3eb7fd22d01f",
   "metadata": {},
   "source": [
    "#### Transformación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626f582c-4bbd-4535-b76a-401d9e5a6fb4",
   "metadata": {},
   "source": [
    "En esta fase, los datos extraídos de la tabla movimientos se transformarán para corregir errores y asegurar la calidad de los datos. Las transformaciones incluyen la eliminación de registros duplicados, la estandarización del formato de fechas y la creación de columnas adicionales para día, mes, año y número de semana ISO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b00e482d-5c6c-4135-916d-f4746135fd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+----------+\n",
      "|FechaTransaccion           |Fecha     |\n",
      "+---------------------------+----------+\n",
      "|2014-02-27                 |2014-02-27|\n",
      "|2014-11-28 12:00:00.0000000|2014-11-28|\n",
      "|2014-06-26 12:00:00.0000000|2014-06-26|\n",
      "|2014-11-19                 |2014-11-19|\n",
      "|2015-02-18                 |2015-02-18|\n",
      "|2015-10-27                 |2015-10-27|\n",
      "|2016-01-27                 |2016-01-27|\n",
      "|2014-08-28                 |2014-08-28|\n",
      "|2014-09-19                 |2014-09-19|\n",
      "|2015-02-12                 |2015-02-12|\n",
      "|2015-01-03                 |2015-01-03|\n",
      "|2015-09-21                 |2015-09-21|\n",
      "|2015-08-22                 |2015-08-22|\n",
      "|2016-05-14                 |2016-05-14|\n",
      "|2014-07-26                 |2014-07-26|\n",
      "|2014-04-18 12:00:00.0000000|2014-04-18|\n",
      "|2013-08-16 12:00:00.0000000|2013-08-16|\n",
      "|2013-04-26                 |2013-04-26|\n",
      "|2013-11-21                 |2013-11-21|\n",
      "|2015-01-16                 |2015-01-16|\n",
      "+---------------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------+----------+---+---+----+-----------------+\n",
      "|idFecha |Fecha     |Dia|Mes|Ano |Numero_semana_ISO|\n",
      "+--------+----------+---+---+----+-----------------+\n",
      "|20140227|2014-02-27|27 |2  |2014|9                |\n",
      "|20141128|2014-11-28|28 |11 |2014|48               |\n",
      "|20140626|2014-06-26|26 |6  |2014|26               |\n",
      "|20141119|2014-11-19|19 |11 |2014|47               |\n",
      "|20150218|2015-02-18|18 |2  |2015|8                |\n",
      "|20151027|2015-10-27|27 |10 |2015|44               |\n",
      "|20160127|2016-01-27|27 |1  |2016|4                |\n",
      "|20140828|2014-08-28|28 |8  |2014|35               |\n",
      "|20140919|2014-09-19|19 |9  |2014|38               |\n",
      "|20150212|2015-02-12|12 |2  |2015|7                |\n",
      "|20150103|2015-01-03|3  |1  |2015|1                |\n",
      "|20150921|2015-09-21|21 |9  |2015|39               |\n",
      "|20150822|2015-08-22|22 |8  |2015|34               |\n",
      "|20160514|2016-05-14|14 |5  |2016|19               |\n",
      "|20140726|2014-07-26|26 |7  |2014|30               |\n",
      "|20140418|2014-04-18|18 |4  |2014|16               |\n",
      "|20130816|2013-08-16|16 |8  |2013|33               |\n",
      "|20130426|2013-04-26|26 |4  |2013|17               |\n",
      "|20131121|2013-11-21|21 |11 |2013|47               |\n",
      "|20150116|2015-01-16|16 |1  |2015|3                |\n",
      "+--------+----------+---+---+----+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_date, col, when, udf, regexp_replace\n",
    "from pyspark.sql.types import StringType, DateType\n",
    "from datetime import datetime\n",
    "\n",
    "# Política de tiempo LEGACY\n",
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\n",
    "\n",
    "# Eliminar registros duplicados basados en FechaTransaccion\n",
    "df_fecha = df_fecha.dropDuplicates([\"FechaTransaccion\"])\n",
    "\n",
    "# Definir una función UDF para convertir el formato 'MMM DD, YYYY' a 'YYYY-MM-DD'\n",
    "def convert_to_date(date_str):\n",
    "    try:\n",
    "        return datetime.strptime(date_str, '%b %d,%Y').strftime('%Y-%m-%d')\n",
    "    except ValueError:\n",
    "        return date_str\n",
    "\n",
    "convert_to_date_udf = udf(convert_to_date, StringType())\n",
    "\n",
    "# Convertir el formato 'MMM DD, YYYY' a 'YYYY-MM-DD'\n",
    "df_fecha = df_fecha.withColumn(\"FechaTransaccion\", convert_to_date_udf(col(\"FechaTransaccion\")))\n",
    "\n",
    "# Convertir fechas que cumplen con el formato 'YYYY-MM-DD HH:MM:SS.0000000' a 'YYYY-MM-DD'\n",
    "df_fecha = df_fecha.withColumn(\"FechaTransaccion\", regexp_replace(col(\"FechaTransaccion\"), \" 00:00:00.0000000\", \"\"))\n",
    "df_fecha = df_fecha.withColumn(\"FechaTransaccion\", regexp_replace(col(\"FechaTransaccion\"), \" 07:00:00.0000000\", \"\"))\n",
    "\n",
    "# Convertir la columna FechaTransaccion a formato de fecha\n",
    "df_fecha = df_fecha.withColumn(\"Fecha\", to_date(col(\"FechaTransaccion\"), \"yyyy-MM-dd\"))\n",
    "\n",
    "# Verificar las fechas parseadas\n",
    "df_fecha.select(\"FechaTransaccion\", \"Fecha\").show(truncate=False)\n",
    "\n",
    "# Crear columnas adicionales para día, mes, año y número de semana ISO\n",
    "df_fecha = df_fecha.withColumn(\"Dia\", f.dayofmonth(f.col(\"Fecha\")))\n",
    "df_fecha = df_fecha.withColumn(\"Mes\", f.month(f.col(\"Fecha\")))\n",
    "df_fecha = df_fecha.withColumn(\"Ano\", f.year(f.col(\"Fecha\")))\n",
    "df_fecha = df_fecha.withColumn(\"Numero_semana_ISO\", f.weekofyear(f.col(\"Fecha\")))\n",
    "\n",
    "# Crear una columna idFecha en el formato YYYYMMDD\n",
    "df_fecha = df_fecha.withColumn(\"idFecha\", f.date_format(f.col(\"Fecha\"), \"yyyyMMdd\").cast(\"int\"))\n",
    "\n",
    "# Seleccionar y renombrar columnas para la tabla destino\n",
    "df_fecha = df_fecha.select(\n",
    "    f.col(\"idFecha\"),\n",
    "    f.col(\"Fecha\"),\n",
    "    f.col(\"Dia\"),\n",
    "    f.col(\"Mes\"),\n",
    "    f.col(\"Ano\"),\n",
    "    f.col(\"Numero_semana_ISO\")\n",
    ")\n",
    "\n",
    "# Mostrar los primeros registros transformados\n",
    "df_fecha.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82726191-c0fe-4c49-a21a-72cc0607725e",
   "metadata": {},
   "source": [
    "#### Carga"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2236f487-93ad-4e77-b179-a708146bbfa5",
   "metadata": {},
   "source": [
    "En esta fase, los datos transformados de la tabla Fecha se cargarán en la tabla de dimensión ETL_Fecha en la base de datos de destino. Se asegurará que los datos se inserten correctamente y se verificará que la estructura de la tabla de destino coincida con los datos transformados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df5fd467-e414-44bc-9bb1-7b362f3ef3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados exitosamente en la tabla ETL_Fecha\n"
     ]
    }
   ],
   "source": [
    "tabla_destino = \"ETL_Fecha\"\n",
    "guardar_db(dest_db_connection_string, df_fecha, tabla_destino, db_user, db_psswd)\n",
    "print(\"Datos cargados exitosamente en la tabla ETL_Fecha\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7c608f-a684-46bf-a89e-244f3ab05cbd",
   "metadata": {},
   "source": [
    "### Hecho_Movimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360d267a-3c1d-4d98-b4a0-9e81b0f872ea",
   "metadata": {},
   "source": [
    "La tabla de hechos Hecho_Movimiento contiene información detallada sobre las transacciones o movimientos de productos en el inventario. Esta tabla de hechos es fundamental para el análisis de las transacciones, permitiendo el análisis en combinación con las diferentes dimensiones como Proveedor, TipoTransaccion, Fecha, Producto y Cliente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88a0d9e-a779-4b1e-80ef-3ca0f53682aa",
   "metadata": {},
   "source": [
    "#### Extracción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d431efd-f44c-46f0-9b41-7d90156a9b9c",
   "metadata": {},
   "source": [
    "En esta fase, se extraen los datos de la tabla movimientos de la base de datos transaccional WWImportersTransactional. La extracción incluye todos los campos necesarios para el análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40b5574a-a134-4142-8eb4-f3fc570bac04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+-----------+---------+-----------------+--------+\n",
      "|FechaTransaccion|ProductoID|ProveedorID|ClienteID|TipoTransaccionID|Cantidad|\n",
      "+----------------+----------+-----------+---------+-----------------+--------+\n",
      "|     Jan 20,2014|       108|       null|    185.0|               10|   -10.0|\n",
      "|     Jan 28,2014|       162|        4.0|      0.0|               11|    10.0|\n",
      "|     Jan 28,2014|       216|       null|    474.0|               10|   -10.0|\n",
      "|     Jan 28,2014|        22|        7.0|      0.0|               11|    10.0|\n",
      "|     Jan 28,2014|        25|        7.0|      0.0|               11|    10.0|\n",
      "|     Feb 01,2014|        14|       null|    444.0|               10|   -10.0|\n",
      "|     Feb 01,2014|        75|        7.0|      0.0|               11|    10.0|\n",
      "|     Mar 25,2014|        20|       null|    802.0|               10|   -10.0|\n",
      "|     Mar 25,2014|        65|        4.0|      0.0|               11|    10.0|\n",
      "|     Mar 25,2014|       130|       null|    487.0|               10|   -10.0|\n",
      "|     Mar 25,2014|       171|        7.0|      0.0|               11|    10.0|\n",
      "|     Mar 25,2014|       118|       null|    129.0|               10|   -10.0|\n",
      "|     Mar 25,2014|       168|        7.0|      0.0|               11|    10.0|\n",
      "|     Mar 25,2014|        52|        7.0|      0.0|               11|    10.0|\n",
      "|     Mar 25,2014|       131|        7.0|      0.0|               11|    10.0|\n",
      "|     Mar 25,2014|       171|       null|    420.0|               10|   -10.0|\n",
      "|     Mar 25,2014|       105|       null|    433.0|               10|   -10.0|\n",
      "|     Mar 25,2014|       112|        4.0|      0.0|               11|    10.0|\n",
      "|     Mar 25,2014|       170|       null|    593.0|               10|   -10.0|\n",
      "|     Mar 25,2014|       132|        4.0|      0.0|               11|    10.0|\n",
      "+----------------+----------+-----------+---------+-----------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_query_movimientos = \"\"\"\n",
    "(SELECT \n",
    "    FechaTransaccion, \n",
    "    ProductoID, \n",
    "    ProveedorID, \n",
    "    ClienteID, \n",
    "    TipoTransaccionID, \n",
    "    Cantidad \n",
    "FROM movimientos_v2) AS movimientos\"\"\"\n",
    "\n",
    "# Extraer los datos de la tabla movimientos\n",
    "df_movimientos = obtener_dataframe_de_bd(source_db_connection_string, sql_query_movimientos, db_user, db_psswd)\n",
    "# Mostrar los primeros registros para verificar \n",
    "df_movimientos.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd09ccd-3dcb-4a37-9a58-f4536b5de5c6",
   "metadata": {},
   "source": [
    "#### Transformación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7894cf7-1a8f-49d7-9776-41e88d026195",
   "metadata": {},
   "source": [
    "En esta fase, los datos extraídos de la tabla movimientos se transformarán para corregir errores y asegurar la calidad de los datos. Las transformaciones incluyen la eliminación de registros duplicados, la corrección de valores negativos en el campo Cantidad, la estandarización del formato de fechas y la combinación de registros con las dimensiones relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4354e688-9e44-4f6f-b8f1-1195a1e65af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+----------+\n",
      "|FechaTransaccion           |Fecha     |\n",
      "+---------------------------+----------+\n",
      "|2016-03-11                 |2016-03-11|\n",
      "|2015-07-27                 |2015-07-27|\n",
      "|2015-09-29                 |2015-09-29|\n",
      "|2016-04-09                 |2016-04-09|\n",
      "|2015-11-06                 |2015-11-06|\n",
      "|2015-09-12                 |2015-09-12|\n",
      "|2016-03-18                 |2016-03-18|\n",
      "|2013-04-13 12:00:00.0000000|2013-04-13|\n",
      "|2015-01-05 12:00:00.0000000|2015-01-05|\n",
      "|2014-12-02 12:00:00.0000000|2014-12-02|\n",
      "|2014-04-09 12:00:00.0000000|2014-04-09|\n",
      "|2013-03-18 12:00:00.0000000|2013-03-18|\n",
      "|2015-01-15 12:00:00.0000000|2015-01-15|\n",
      "|2014-07-04 12:00:00.0000000|2014-07-04|\n",
      "|2013-01-16                 |2013-01-16|\n",
      "|2014-05-21                 |2014-05-21|\n",
      "|2015-01-24                 |2015-01-24|\n",
      "|2014-04-30                 |2014-04-30|\n",
      "|2015-09-21                 |2015-09-21|\n",
      "|2014-04-11                 |2014-04-11|\n",
      "+---------------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----------+\n",
      "|Fecha     |\n",
      "+----------+\n",
      "|2015-05-19|\n",
      "|2016-03-01|\n",
      "|2014-09-26|\n",
      "|2015-03-09|\n",
      "|2014-11-12|\n",
      "|2013-09-09|\n",
      "|2013-05-21|\n",
      "|2013-03-26|\n",
      "|2013-01-22|\n",
      "|2015-03-06|\n",
      "|2016-04-25|\n",
      "|2013-09-19|\n",
      "|2014-08-01|\n",
      "|2015-09-02|\n",
      "|2015-12-22|\n",
      "|2016-05-03|\n",
      "|2015-04-09|\n",
      "|2013-02-02|\n",
      "|2014-06-03|\n",
      "|2016-01-28|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------+---------------+----------------+--------------+-----------------------+--------+\n",
      "|idFecha |ID_Producto_DWH|ID_Proveedor_DWH|ID_Cliente_DWH|ID_Tipo_Transaccion_DWH|Cantidad|\n",
      "+--------+---------------+----------------+--------------+-----------------------+--------+\n",
      "|20140128|162            |4               |0             |11                     |10      |\n",
      "|20140128|162            |4               |0             |11                     |10      |\n",
      "|20140128|162            |4               |0             |11                     |10      |\n",
      "|20140128|216            |0               |474           |10                     |-10     |\n",
      "|20140128|216            |0               |474           |10                     |-10     |\n",
      "|20140128|216            |0               |474           |10                     |-10     |\n",
      "|20140128|22             |7               |0             |11                     |10      |\n",
      "|20140128|22             |7               |0             |11                     |10      |\n",
      "|20140128|22             |7               |0             |11                     |10      |\n",
      "|20140128|25             |7               |0             |11                     |10      |\n",
      "|20140128|25             |7               |0             |11                     |10      |\n",
      "|20140128|25             |7               |0             |11                     |10      |\n",
      "|20140120|108            |0               |185           |10                     |-10     |\n",
      "|20140120|108            |0               |185           |10                     |-10     |\n",
      "|20140120|108            |0               |185           |10                     |-10     |\n",
      "|20140325|20             |0               |802           |10                     |-10     |\n",
      "|20140325|20             |0               |802           |10                     |-10     |\n",
      "|20140325|20             |0               |802           |10                     |-10     |\n",
      "|20140325|65             |4               |0             |11                     |10      |\n",
      "|20140325|65             |4               |0             |11                     |10      |\n",
      "+--------+---------------+----------------+--------------+-----------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_date, col, when, udf, regexp_replace\n",
    "from pyspark.sql.types import StringType\n",
    "from datetime import datetime\n",
    "\n",
    "# Definir una función UDF para convertir el formato 'MMM DD, YYYY' a 'YYYY-MM-DD'\n",
    "def convert_to_date(date_str):\n",
    "    try:\n",
    "        return datetime.strptime(date_str, '%b %d,%Y').strftime('%Y-%m-%d')\n",
    "    except ValueError:\n",
    "        return date_str\n",
    "\n",
    "convert_to_date_udf = udf(convert_to_date, StringType())\n",
    "\n",
    "# Convertir el formato 'MMM DD, YYYY' a 'YYYY-MM-DD'\n",
    "df_movimientos = df_movimientos.withColumn(\"FechaTransaccion\", convert_to_date_udf(col(\"FechaTransaccion\")))\n",
    "\n",
    "# Eliminar partes innecesarias del tiempo en las fechas\n",
    "df_movimientos = df_movimientos.withColumn(\"FechaTransaccion\", regexp_replace(col(\"FechaTransaccion\"), \" 00:00:00.0000000\", \"\"))\n",
    "df_movimientos = df_movimientos.withColumn(\"FechaTransaccion\", regexp_replace(col(\"FechaTransaccion\"), \" 07:00:00.0000000\", \"\"))\n",
    "\n",
    "# Convertir la columna FechaTransaccion a formato de fecha\n",
    "df_movimientos = df_movimientos.withColumn(\"Fecha\", to_date(f.col(\"FechaTransaccion\"), \"yyyy-MM-dd\"))\n",
    "\n",
    "# Verificar las fechas parseadas correctamente\n",
    "df_movimientos.select(\"FechaTransaccion\", \"Fecha\").distinct().show(truncate=False)\n",
    "df_fecha.select(\"Fecha\").distinct().show(truncate=False)\n",
    "\n",
    "# Asignar 0 a ProveedorID si es null\n",
    "df_movimientos = df_movimientos.withColumn(\"ProveedorID\", f.when(f.col(\"ProveedorID\").isNull(), 0).otherwise(f.col(\"ProveedorID\")))\n",
    "\n",
    "# Unir con la dimensión Fecha para obtener el idFecha\n",
    "df_movimientos = df_movimientos.join(df_fecha.select(\"Fecha\", \"idFecha\"), on=\"Fecha\", how=\"left\")\n",
    "\n",
    "# Convertir columnas a tipos de datos enteros para eliminar decimales\n",
    "df_movimientos = df_movimientos.withColumn(\"ID_Proveedor_DWH\", f.col(\"ProveedorID\").cast(\"int\"))\n",
    "df_movimientos = df_movimientos.withColumn(\"ID_Cliente_DWH\", f.col(\"ClienteID\").cast(\"int\"))\n",
    "df_movimientos = df_movimientos.withColumn(\"ID_Tipo_Transaccion_DWH\", f.col(\"TipoTransaccionID\").cast(\"int\"))\n",
    "df_movimientos = df_movimientos.withColumn(\"Cantidad\", f.col(\"Cantidad\").cast(\"int\"))\n",
    "\n",
    "# Seleccionar y renombrar columnas para la tabla destino\n",
    "df_movimientos = df_movimientos.select(\n",
    "    f.col(\"idFecha\"),\n",
    "    f.col(\"ProductoID\").alias(\"ID_Producto_DWH\"),\n",
    "    f.col(\"ID_Proveedor_DWH\"),\n",
    "    f.col(\"ID_Cliente_DWH\"),\n",
    "    f.col(\"ID_Tipo_Transaccion_DWH\"),\n",
    "    f.col(\"Cantidad\")\n",
    ")\n",
    "\n",
    "# Mostrar los primeros registros transformados\n",
    "df_movimientos.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb28d446-56be-4692-9830-1d4ad18e8a17",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Carga"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1443629-5a0a-49b7-b78d-b64818d9859e",
   "metadata": {},
   "source": [
    "En esta fase, los datos transformados de la tabla movimientos se cargarán en la tabla de hechos ETL_Hecho_Movimiento en la base de datos de destino. Se asegurará que los datos se inserten correctamente y se verificará que la estructura de la tabla de destino coincida con los datos transformados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "374c5279-abaa-480b-8020-630e8ee6fde6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados exitosamente en la tabla ETL_Hecho_Movimiento\n"
     ]
    }
   ],
   "source": [
    "tabla_destino = \"ETL_Hecho_Movimiento\"\n",
    "guardar_db(dest_db_connection_string, df_movimientos, tabla_destino, db_user, db_psswd)\n",
    "print(\"Datos cargados exitosamente en la tabla ETL_Hecho_Movimiento\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7773e467-f21a-4f80-9ace-ad5a38e2b9a0",
   "metadata": {},
   "source": [
    "## Reglas del negocio "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2847ea3a-4f98-4c12-81a4-3f2cbba3157b",
   "metadata": {},
   "source": [
    "### Los días de pago no pueden ser negativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ce9cdb5-507a-4e89-9ed5-f1fa277b727e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------+---------+--------------------------+------------------------+--------+------------+\n",
      "|ID_Proveedor_T|NombreProveedor|Categoria|PersonaContactoPrincipalID|PersonaContactoAlternoID|DiasPago|CodigoPostal|\n",
      "+--------------+---------------+---------+--------------------------+------------------------+--------+------------+\n",
      "+--------------+---------------+---------+--------------------------+------------------------+--------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_proveedor = obtener_dataframe_de_bd(dest_db_connection_string, 'ETL_Proveedor', db_user, db_psswd)\n",
    "# Verificar registros con DiasPago negativo\n",
    "df_proveedor_negativos = df_proveedor.filter(df_proveedor[\"DiasPago\"] < 0)\n",
    "df_proveedor_negativos.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33ca4d7-5ad5-487b-8668-62a82b23d4ab",
   "metadata": {},
   "source": [
    "### Verificar datos antes de 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76cf88d8-1d23-4351-b4c8-a308a6bf72a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+----------------+--------------+-----------------------+--------+-----------+\n",
      "|idFecha |ID_Producto_DWH|ID_Proveedor_DWH|ID_Cliente_DWH|ID_Tipo_Transaccion_DWH|Cantidad|idFecha_str|\n",
      "+--------+---------------+----------------+--------------+-----------------------+--------+-----------+\n",
      "|20131116|45             |0               |6             |10                     |-10     |20131116   |\n",
      "|20131116|210            |0               |933           |10                     |-10     |20131116   |\n",
      "|20131116|4              |0               |448           |10                     |-10     |20131116   |\n",
      "|20131116|24             |0               |71            |10                     |-10     |20131116   |\n",
      "|20131116|44             |0               |446           |10                     |-10     |20131116   |\n",
      "|20131116|16             |0               |566           |10                     |-10     |20131116   |\n",
      "|20131116|62             |4               |0             |11                     |10      |20131116   |\n",
      "|20131116|26             |7               |0             |11                     |10      |20131116   |\n",
      "|20130116|52             |0               |8             |10                     |-10     |20130116   |\n",
      "|20130116|52             |0               |8             |10                     |-10     |20130116   |\n",
      "|20130116|8              |4               |0             |11                     |10      |20130116   |\n",
      "|20130116|8              |4               |0             |11                     |10      |20130116   |\n",
      "|20130116|109            |4               |0             |11                     |10      |20130116   |\n",
      "|20130116|109            |4               |0             |11                     |10      |20130116   |\n",
      "|20130116|109            |4               |0             |11                     |10      |20130116   |\n",
      "|20130116|109            |4               |0             |11                     |10      |20130116   |\n",
      "|20130116|15             |7               |0             |11                     |10      |20130116   |\n",
      "|20130116|15             |7               |0             |11                     |10      |20130116   |\n",
      "|20130116|106            |0               |524           |10                     |-10     |20130116   |\n",
      "|20130116|106            |0               |524           |10                     |-10     |20130116   |\n",
      "+--------+---------------+----------------+--------------+-----------------------+--------+-----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Número de registros con fechas anteriores a 2014: 122199\n"
     ]
    }
   ],
   "source": [
    "df_hecho_movimiento = obtener_dataframe_de_bd(dest_db_connection_string, 'ETL_Hecho_Movimiento', db_user, db_psswd)\n",
    "\n",
    "# Convertir la columna idFecha a String para poder filtrar por año\n",
    "df_hecho_movimiento = df_hecho_movimiento.withColumn(\"idFecha_str\", f.col(\"idFecha\").cast(\"string\"))\n",
    "\n",
    "# Filtrar registros con fechas anteriores a 2014\n",
    "df_antes_2014 = df_hecho_movimiento.filter(f.col(\"idFecha_str\").substr(1, 4) < '2014')\n",
    "\n",
    "# Mostrar los registros anteriores a 2014\n",
    "df_antes_2014.show(truncate=False)\n",
    "\n",
    "# Contar el número de registros anteriores a 2014\n",
    "count_antes_2014 = df_antes_2014.count()\n",
    "\n",
    "print(f\"Número de registros con fechas anteriores a 2014: {count_antes_2014}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9254c01-ce0b-461a-955c-81452c6e8b3b",
   "metadata": {},
   "source": [
    "### Validar duplicados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd5bacc1-f339-4918-99d8-093f586f80a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+----------------+--------------+-----------------------+--------+-----+\n",
      "| idFecha|ID_Producto_DWH|ID_Proveedor_DWH|ID_Cliente_DWH|ID_Tipo_Transaccion_DWH|Cantidad|count|\n",
      "+--------+---------------+----------------+--------------+-----------------------+--------+-----+\n",
      "|20150519|            113|               0|           879|                     10|     -10|    3|\n",
      "|20151027|             73|               4|             0|                     11|       5|    3|\n",
      "|20151027|             59|               4|             0|                     11|       2|    3|\n",
      "|20150106|             13|               4|             0|                     11|       1|    3|\n",
      "|20130116|            143|               4|             0|                     11|      12|    2|\n",
      "|20150309|            104|               0|           426|                     10|      -8|    3|\n",
      "|20130521|             26|               0|           972|                     10|      -5|    2|\n",
      "|20130521|            132|               7|             0|                     11|       4|    2|\n",
      "|20140926|             31|               0|           138|                     10|      -6|    3|\n",
      "|20131101|             36|               7|             0|                     11|       2|    2|\n",
      "|20150324|            127|               0|           489|                     10|      -1|    3|\n",
      "|20140926|            161|               0|           509|                     10|     -20|    3|\n",
      "|20150309|            201|               7|             0|                     11|     168|    3|\n",
      "|20150413|             93|               4|             0|                     11|      36|    3|\n",
      "|20150306|            122|               4|             0|                     11|       9|    3|\n",
      "|20130919|            154|               0|           565|                     10|    -100|    2|\n",
      "|20150902|            211|               7|             0|                     11|      10|    3|\n",
      "|20150902|            110|               4|             0|                     11|      10|    3|\n",
      "|20150717|            205|               0|           890|                     10|     -20|    3|\n",
      "|20150902|             68|               7|             0|                     11|       1|    3|\n",
      "+--------+---------------+----------------+--------------+-----------------------+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verificar duplicados en ETL_Hecho_Movimiento\n",
    "df_hecho_movimiento = obtener_dataframe_de_bd(dest_db_connection_string, 'ETL_Hecho_Movimiento', db_user, db_psswd)\n",
    "df_hecho_movimiento_duplicados = df_hecho_movimiento.groupBy(\"idFecha\", \"ID_Producto_DWH\", \"ID_Proveedor_DWH\", \"ID_Cliente_DWH\", \"ID_Tipo_Transaccion_DWH\", \"Cantidad\").count().filter(\"count > 1\")\n",
    "df_hecho_movimiento_duplicados.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbb1d62-32ac-40c8-ab86-1a5ac063f653",
   "metadata": {},
   "source": [
    "### Validar formato de fechas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d774c8ba-0057-4b8b-8d59-b3995727104e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+---+---+---+-----------------+\n",
      "|idFecha|Fecha|Dia|Mes|Ano|Numero_semana_ISO|\n",
      "+-------+-----+---+---+---+-----------------+\n",
      "+-------+-----+---+---+---+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verificar el formato de las fechas en ETL_Fecha\n",
    "df_fecha = obtener_dataframe_de_bd(dest_db_connection_string, 'ETL_Fecha', db_user, db_psswd)\n",
    "df_fecha_formato = df_fecha.filter(~(f.col(\"Fecha\").like(\"____-__-__\") | ((f.length(\"Fecha\") > 10) & f.col(\"Fecha\").like(\"____-__-__ __:__:__\"))))\n",
    "df_fecha_formato.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07815dce-574e-4f45-b343-35a1bdcd8368",
   "metadata": {},
   "source": [
    "### Verificar nombres de proveedores unificados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25bd0e6-4b88-47e9-b7c2-0dd1647475a2",
   "metadata": {},
   "source": [
    "Confirmar que los proveedores con nombres duplicados (con o sin \"Inc\" o \"Ltd\") se hayan unificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98c8ef18-9e4d-4622-bc7c-9e4c6fa95682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+-------------------+--------------------------+------------------------+--------+------------+\n",
      "|ID_Proveedor_T|     NombreProveedor|          Categoria|PersonaContactoPrincipalID|PersonaContactoAlternoID|DiasPago|CodigoPostal|\n",
      "+--------------+--------------------+-------------------+--------------------------+------------------------+--------+------------+\n",
      "|             1| A Datum Corporation|productos novedosos|                        21|                      22|      14|       46077|\n",
      "|             2|       Contoso, Ltd.|productos novedosos|                        23|                      24|       7|       98253|\n",
      "|             5|Graphic Design In...|productos novedosos|                        29|                      30|      14|       64847|\n",
      "|             8|  Lucerne Publishing|productos novedosos|                        35|                      36|      30|       37659|\n",
      "|             9|      Nod Publishers|productos novedosos|                        37|                      38|       7|       27906|\n",
      "+--------------+--------------------+-------------------+--------------------------+------------------------+--------+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------------------------+-----+\n",
      "|NombreProveedorEstandarizado|count|\n",
      "+----------------------------+-----+\n",
      "+----------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_proveedor = obtener_dataframe_de_bd(dest_db_connection_string, 'ETL_Proveedor', db_user, db_psswd)\n",
    "\n",
    "# Mostrar los primeros registros para verificar\n",
    "df_proveedor.show(5)\n",
    "\n",
    "# Normalizar los nombres de los proveedores eliminando \"Inc\" y \"Ltd\" para la comprobación\n",
    "df_proveedor_norm = df_proveedor.withColumn(\"NombreProveedorEstandarizado\", \n",
    "                                            f.trim(f.regexp_replace(f.col(\"NombreProveedor\"), \"(?i)\\\\s*Inc\\\\.?|(?i)\\\\s*Ltd\\\\.?\", \"\")))\n",
    "\n",
    "# Agrupar y contar los proveedores normalizados para verificar duplicados\n",
    "df_proveedor_duplicados = df_proveedor_norm.groupBy(\"NombreProveedorEstandarizado\").count().filter(\"count > 1\")\n",
    "\n",
    "# Mostrar los proveedores duplicados\n",
    "df_proveedor_duplicados.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389a40ae-3f4c-439a-93f3-4fa610af2102",
   "metadata": {},
   "source": [
    "### Verificar el código postal de los Proveedores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "203218b1-5b58-4c44-810d-64dd59222637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+-------------------+--------------------------+------------------------+--------+------------+\n",
      "|ID_Proveedor_T|     NombreProveedor|          Categoria|PersonaContactoPrincipalID|PersonaContactoAlternoID|DiasPago|CodigoPostal|\n",
      "+--------------+--------------------+-------------------+--------------------------+------------------------+--------+------------+\n",
      "|             1| A Datum Corporation|productos novedosos|                        21|                      22|      14|       46077|\n",
      "|             2|       Contoso, Ltd.|productos novedosos|                        23|                      24|       7|       98253|\n",
      "|             5|Graphic Design In...|productos novedosos|                        29|                      30|      14|       64847|\n",
      "|             8|  Lucerne Publishing|productos novedosos|                        35|                      36|      30|       37659|\n",
      "|             9|      Nod Publishers|productos novedosos|                        37|                      38|       7|       27906|\n",
      "+--------------+--------------------+-------------------+--------------------------+------------------------+--------+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------------+-----+\n",
      "|CodigoPostal|count|\n",
      "+------------+-----+\n",
      "|       94101|    2|\n",
      "+------------+-----+\n",
      "\n",
      "+--------------+----------------------+-----------------------+--------------------------+------------------------+--------+------------+\n",
      "|ID_Proveedor_T|NombreProveedor       |Categoria              |PersonaContactoPrincipalID|PersonaContactoAlternoID|DiasPago|CodigoPostal|\n",
      "+--------------+----------------------+-----------------------+--------------------------+------------------------+--------+------------+\n",
      "|3             |Consolidated Messenger|servicios de mensajeria|25                        |26                      |30      |94101       |\n",
      "|13            |Woodgrove Bank        |servicios financieros  |45                        |46                      |7       |94101       |\n",
      "+--------------+----------------------+-----------------------+--------------------------+------------------------+--------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_proveedor = obtener_dataframe_de_bd(dest_db_connection_string, 'ETL_Proveedor', db_user, db_psswd)\n",
    "\n",
    "# Mostrar los primeros registros para verificar\n",
    "df_proveedor.show(5)\n",
    "\n",
    "# Agrupar por CodigoPostal y contar las ocurrencias\n",
    "df_codigo_postal_repetido = df_proveedor.groupBy(\"CodigoPostal\").count().filter(\"count > 1\")\n",
    "\n",
    "# Mostrar el código postal que se repite y el número de ocurrencias\n",
    "df_codigo_postal_repetido.show()\n",
    "\n",
    "# Obtener el código postal que se repite\n",
    "codigo_postal_repetido = df_codigo_postal_repetido.select(\"CodigoPostal\").collect()\n",
    "\n",
    "# Verificar si hay un código postal repetido\n",
    "if len(codigo_postal_repetido) > 0:\n",
    "    codigo_postal_repetido = codigo_postal_repetido[0][\"CodigoPostal\"]\n",
    "    \n",
    "    # Filtrar proveedores con el código postal repetido\n",
    "    df_proveedores_duplicados = df_proveedor.filter(f.col(\"CodigoPostal\") == codigo_postal_repetido)\n",
    "    \n",
    "    # Mostrar los proveedores asociados al código postal repetido\n",
    "    df_proveedores_duplicados.show(truncate=False)\n",
    "else:\n",
    "    print(\"No hay códigos postales repetidos.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b0f4b8-ddfc-4306-bd68-ed5e3d5b4bee",
   "metadata": {},
   "source": [
    "Validamos que tanto Consolidated Messenger y Woodgrove Bank tienen el mismo código postal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30b51061-3305-465e-a473-37ac96b5143c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+----------------+--------------+-----------------------+--------+-----+\n",
      "| idFecha|ID_Producto_DWH|ID_Proveedor_DWH|ID_Cliente_DWH|ID_Tipo_Transaccion_DWH|Cantidad|count|\n",
      "+--------+---------------+----------------+--------------+-----------------------+--------+-----+\n",
      "|20150519|            113|               0|           879|                     10|     -10|    3|\n",
      "|20151027|             73|               4|             0|                     11|       5|    3|\n",
      "|20151027|             59|               4|             0|                     11|       2|    3|\n",
      "|20150106|             13|               4|             0|                     11|       1|    3|\n",
      "|20130116|            143|               4|             0|                     11|      12|    2|\n",
      "|20150309|            104|               0|           426|                     10|      -8|    3|\n",
      "|20130521|             26|               0|           972|                     10|      -5|    2|\n",
      "|20130521|            132|               7|             0|                     11|       4|    2|\n",
      "|20140926|             31|               0|           138|                     10|      -6|    3|\n",
      "|20131101|             36|               7|             0|                     11|       2|    2|\n",
      "|20150324|            127|               0|           489|                     10|      -1|    3|\n",
      "|20140926|            161|               0|           509|                     10|     -20|    3|\n",
      "|20150413|             93|               4|             0|                     11|      36|    3|\n",
      "|20150309|            201|               7|             0|                     11|     168|    3|\n",
      "|20150306|            122|               4|             0|                     11|       9|    3|\n",
      "|20130919|            154|               0|           565|                     10|    -100|    2|\n",
      "|20150717|            205|               0|           890|                     10|     -20|    3|\n",
      "|20150902|            211|               7|             0|                     11|      10|    3|\n",
      "|20150902|            110|               4|             0|                     11|      10|    3|\n",
      "|20150902|             68|               7|             0|                     11|       1|    3|\n",
      "+--------+---------------+----------------+--------------+-----------------------+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verificar duplicados en la tabla de destino ETL_Hecho_Movimiento\n",
    "df_hecho_movimiento = obtener_dataframe_de_bd(dest_db_connection_string, 'ETL_Hecho_Movimiento', db_user, db_psswd)\n",
    "\n",
    "# Agrupar y contar registros duplicados\n",
    "df_hecho_movimiento_duplicados = df_hecho_movimiento.groupBy(\"idFecha\", \"ID_Producto_DWH\", \"ID_Proveedor_DWH\", \"ID_Cliente_DWH\", \"ID_Tipo_Transaccion_DWH\", \"Cantidad\").count().filter(\"count > 1\")\n",
    "\n",
    "# Mostrar registros duplicados\n",
    "df_hecho_movimiento_duplicados.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e40c4dc-cdaf-4faa-9624-236e627125c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros después de la unión: 595683\n"
     ]
    }
   ],
   "source": [
    "# Verificar si hay registros adicionales generados por la unión con dimensiones\n",
    "df_fecha = obtener_dataframe_de_bd(dest_db_connection_string, 'ETL_Fecha', db_user, db_psswd)\n",
    "df_movimientos = obtener_dataframe_de_bd(source_db_connection_string, 'movimientos', db_user, db_psswd)\n",
    "\n",
    "# Realizar la unión original y contar registros\n",
    "df_movimientos = df_movimientos.withColumn(\"Fecha\", to_date(f.col(\"FechaTransaccion\"), \"yyyy-MM-dd\"))\n",
    "df_movimientos = df_movimientos.join(df_fecha.select(\"Fecha\", \"idFecha\"), \"Fecha\", \"left\")\n",
    "\n",
    "# Contar registros después de la unión\n",
    "num_registros_union = df_movimientos.count()\n",
    "\n",
    "print(f\"Número de registros después de la unión: {num_registros_union}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f44273d-4a37-4451-9a08-9e00fdd8f139",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
